---
title: Teleport Server Access SSH Guide
description: Teleport Server Access SSH guide.
---

Teleport Server Access can be used with third-party SSH tools like [OpenSSH](./openssh.mdx). Each Teleport Node can also be configured into a dedicated SSH mode (Node mode) and run as an enhanced SSH server.

`tsh` is a command line client with support for both SCP and SSH that's used to interact with Teleport Nodes. As such, Teleport admins can choose to use `tsh` alone for SSH-related server access and reduce the complexity of their stack.

This Guide describes common scenarios one is likely to encounter when using Teleport as an SSH server, as an SSH client, or both.

## Choose your SSH solution

SSH tools are now commonly distributed as clients, servers, or some combination of both.  

Teleport is unopinionated and agnostic about which client and/or server you choose. Admins can select specific Teleport features (like [Session Recording](../../features/enhanced-session-recording.mdx) while opting to continue using some or all of their existing SSH solutions.

Teleport features can be used to "wrap" or enhance existing SSH tools while retaining the original, underlying, SSH access flows already in place.

<Admonition title="Tip" type="tip">
  For an added layer of secrecy, the default Teleport listening ports can be overridden by port numbers of your choice using Teleport YAML configuration files.
</Admonition>

### Clients

Teleport is compatible with popular clients like [OpenSSH](./openssh.mdx) and also provides its own [built-in SSH client](../../cli-docs.mdx#tsh) (`tsh`).

By default, SSH clients can connect to a Teleport cluster through the following port (exposed through the public proxy):

| Port | Service | Description |
| - | - | - |
| 3023 | Proxy | SSH port clients connect to. A proxy will forward this connection to port `#3022` on the destination Node. |

Teleport allows for complex, multi-client, arrangments as well as unified solutions (using Teleport alone in both a dedicated SSH server and as a client through `tsh`). For example, one cluster may be accessible through OpenSSH, another through Teleport `tsh`, and another through Putty.
  
### Servers

Teleport is agnostic concerning your choice of SSH server backends and can be used to supplement existing features or serve as an intermediary between them and public clients.

A common strategy involves using Teleport Nodes in Proxy mode to get all the benefits of Audit Logging, Session Recording, and/or 2FA.

Most backends likely expose port `22` for inbound public clients and `tsh` will connect through the specified `--port` value on command:

```bash
# tsh ssh into a public proxy Node using a specific port
tsh ssh --port=22 user@tele.example.com
```

## SSH mode and adding an SSH Node to your cluster

Teleport [Nodes](../../architecture/nodes.mdx) have three modes: *Auth*, *Proxy*, and *Node* (SSH) mode. A single Node can run in up to all three modes. Optionally, you can configure a Node to act as the dedicated *Auth* or SSH Node for a cluster.

<Figure
  align="center"
  bordered
  caption="Teleport SSH agent forwarding."
>
  ![Example cluster arrangement](../../../img/server-access/teleport-ssh.svg)
</Figure>

### Configuration

The two primary ways a Node can be configured into SSH (or any) mode is through a `teleport.yaml` configuration file or via the `sudo tctl tokens add` command which accepts the `--type` parameter to specify which of `auth`, `proxy`, or `node` (default) the Node will be automatically configured as.

In both cases, you'll likely use a *static* (fixed) or *dynamic* (valid for a limited duration of time) [join token](../../admin-guide.mdx#adding-nodes-to-the-cluster) to link your Nodes to existing clusters.

<Admonition type="warning" title="Warning">
  The examples below may include the use of the `sudo` keyword to make following each step easier when creating resources from scratch. However, we generally discourage the use of `sudo` in real-world production environments per the *Principle of Least Privilege* (POLP). 
</Admonition>

To link an SSH Node with an existing `tele.example.com` cluster:

1. Create a *join token* to add the new Node to the `tele.example.com` cluster. On the existing Node run the following command to generate a join token:

   ```bash
   # Let's save the token to a file
   sudo tctl tokens add --type=node | grep -oP '(?<=token:\s).*' > token.file
   ```
 
   Each Teleport Node can be configured into SSH mode (Teleport Node) and run as an enhanced SSH server. "Node" mode specifies that the Teleport Node will act and join as an SSH server.  
   
   `> token.file` indicates that you'd like to save the output to a file name `token.file`.
  
   <Admonition type="tip" title="Tip">
     This helps to minimize the direct sharing of tokens even when they are *dynamically* generated.   
   </Admonition>

2. Open a terminal on the new Node to be added and connect to `tele.example.com`.
   
   - Save `token.file` to an appropriate, secure, directory you have the rights and access to read on the second instance. 

   ```bash
   # Join cluster
   sudo teleport start \
     --roles=node \
     --token=./token.file \
     --auth-server=tele.example.com:443
   ```

   - Replace the `auth-server` value with the public proxy address of the machine you wish to connect to. By default, the subdomain `tele.example.com` will be available on port `443`.
   - Supply the secured path to the new Node's `token.file`.

3. You should now be able to view both Nodes in the Teleport Web interface after logging in with a user that has permission to view the cluster's resources:

   <Figure
     align="center"
     bordered
     caption="Both Nodes in the Web UI"
   >
     ![Both Nodes in the Web UI](../../../img/server-access/teleport_ui.png)
   </Figure>

## Connect to a cluster using tsh ssh

Teleport SSH is robust enough that you can do all the things you'd do with OpenSSH, without it.

To `tsh` into a cluster at `tele.example.com` with user `tele-admin`:

1. On your local machine, log in through `tsh`: 

   ```bash
   # Log in through tsh
   tsh login --proxy=tele.example.com:443 --user=tele-admin
   ```
   
   You'll be prompted to supply the password and One Time Passcode we set up previously.

2. `tele-admin` will now see:

   ```bash
   Profile URL:        https://tele.example.com:443
     Logged in as:       tele-admin
     Cluster:            tele.example.com
     Roles:              access, editor
     Logins:             root, ubuntu, ec2-user
     Kubernetes:         disabled
     Valid until:        2021-04-30 06:39:13 -0500 CDT [valid for 12h0m0s]
     Extensions:         permit-agent-forwarding, permit-port-forwarding, permit-pty
   ```

   `tele-admin` is now logged into the `tele.example.com` cluster through Teleport SSH.

3. `tele-admin` can now execute the following to find the cluster's `nodenames`. `nodenames` are used for establishing SSH connections:

   ```bash
   # Display cluster resources
   tsh ls
   ```

   The *Bastion Host* Node is located on the bottom line below:

   ```bash                        
   Node Name        Address        Labels                                 
   ---------------- -------------- -------------------------------------- 
   ip-172-31-35-170 ‚üµ Tunnel                                              
   ip-172-31-41-144 127.0.0.1:3022 env=example, hostname=ip-172-31-41-144 
   ```

4. `tele-admin` can SSH any available Node they have been granted access to by running the following command locally:

   ```bash
   # Use tsh to ssh into a Node
   tsh ssh root@ip-xxx-xx-xx-xxx
   ```

   Now, `tele-admin` can:

   - Connect to other Nodes in the cluster by using the appropriate IP address in the `tsh ssh` command.  
   - Traverse the Linux file system.  
   - Execute desired commands.  

   All commands executed by `tele-admin` are recorded and can be replayed in the Teleport Web interface.
   
   The `tsh ssh` command allows one to do anything they would if they were to SSH into a server using a third-party tool. Compare the two equivalent commands:

<Tabs>
  <TabItem label="tsh">
    ```bash
    tsh ssh root@ip-172-31-41-144
    ```
  </TabItem>
  <TabItem label="ssh">
    ```bash
    ssh -J tele.example.com root@ip-172-31-41-144
    ```
  </TabItem>
</Tabs>

## Connecting to SSH clusters behind firewalls

Teleport supports creating clusters of servers located behind firewalls
**without any open listening TCP ports**.  This works by creating reverse SSH
tunnels from behind-firewall environments into a Teleport proxy you have access to.

These features are called [*Trusted Clusters*](https://gravitational.com/teleport/docs/trustedclusters/). Refer to
[the admin manual](../../admin-guide.mdx#trusted-clusters) to learn how a trusted cluster can be configured.

Assuming the `work` Teleport proxy server is configured with a few trusted
clusters, a user may use the `tsh clusters` command to see a list of all clusters on the server:

```bash
tsh --proxy=work clusters

# Cluster Name     Status
# ------------     ------
# staging          online
# production       offline
```

[CLI Docs - tsh clusters](../../cli-docs.mdx#tsh-clusters)

Now you can use the `--cluster` flag with any `tsh` command. For example, to list SSH nodes that are members of the `production` cluster, simply do:

```bash
tsh --proxy=work ls --cluster=production
# Node Name     Node ID       Address            Labels
# ---------     -------       -------            ------
# db-1          xxxxxxxxx     10.0.20.31:3022    kernel:4.4
# db-2          xxxxxxxxx     10.0.20.41:3022    kernel:4.2
```

Similarly, if you want to SSH into `db-1` inside the `production` cluster:

```bash
tsh --proxy=work ssh --cluster=production db-1
```

This is possible even if nodes in the `production` cluster are located behind a
firewall without open ports. This works because the `production` cluster
establishes a reverse SSH tunnel back into `work` proxy, and this tunnel is used
to establish inbound SSH connections.
